- title: "Efficiently Using LLMs in Your Apps and Securing Them with Guard Rails"
  date: "2024"
  thumbnail: /assets/images/video efficiently use llms.png
  details: |
    <div style="text-align: center; margin: 20px 0;">
      <iframe width="100%" height="315" src="https://www.youtube.com/embed/GU-vhQFXEVM?si=LUdjSOfHVUiSVPKS" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen style="border-radius: 10px; box-shadow: 0 4px 15px rgba(0,0,0,0.2);"></iframe>
    </div>
    
    <h4>AI Summit Conference Talk</h4>
    <p>A comprehensive presentation delivered at the <strong>School of AI Algiers AI Summit</strong> covering efficiency and security in Large Language Model applications. This talk provides practical insights for developers and engineers working with LLM-powered systems.</p>
    
    <h4>Key Topics Covered</h4>
    <p>The presentation is structured in two main parts covering essential aspects of LLM deployment:</p>
    <ul>
      <li><strong>Efficiency Techniques:</strong> Six tools and techniques for optimizing LLM usage, including when to avoid LLMs entirely, choosing between open-source and closed-source models, and GPU optimization strategies</li>
      <li><strong>Security with Guard Rails:</strong> Comprehensive coverage of input and output validation, prompt injection prevention, and automated security measures</li>
      <li><strong>Practical Implementation:</strong> Real-world examples including database query generation, structured output formatting, and cost optimization strategies</li>
      <li><strong>Advanced Concepts:</strong> Fine-tuning considerations, RAG implementation, agentic workflows, and hardware optimization techniques</li>
    </ul>
    
    <h4>Technical Insights</h4>
    <p>The talk demonstrates practical applications including constrained decoding, prompt caching, model quantization, and the implementation of Teacher-Student curriculum learning. Special emphasis is placed on environmental considerations and cost-effective deployment strategies.</p>
    
    <h4>Community Impact</h4>
    <p>Delivered to the AI community as part of ongoing knowledge sharing initiatives, this presentation reflects expertise gained from published research in 5G-LLM fine-tuning and practical experience in MLOps engineering.</p>
